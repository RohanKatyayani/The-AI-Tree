# Linear Regression

### One-Liner:
*   **What it is:** A fundamental supervised learning algorithm used for predicting a continuous numerical value by fitting a straight line to the data points.

### The Big Picture:
Linear Regression is one of the simplest and most widely used **leaves** on the **Supervised Learning** branch, specifically for **regression** tasks. It's the go-to starting point for predicting numerical outcomes.

### How it Works (The Core Idea):
The algorithm finds the best-fitting straight line (y = mx + b) through the data points. It calculates this line by minimizing the total distance between itself and all the points (the "error"). The line can then be used to predict new values.

### Why it Matters:
It's simple, interpretable, and fast. It provides a clear understanding of the relationship between the input feature (x) and the output prediction (y). If the relationship is roughly linear, it can be very effective.

### A Simple Analogy:
Predicting pizza price based on its size.
*   **Input (x):** Diameter of the pizza (in inches).
*   **Output (y):** Price of the pizza (in dollars).
You plot past pizzas on a graph and draw the best straight line through them. Now, for a new 16-inch pizza, you can use the line to predict its price.

### Real-World Examples:
*   Predicting house prices based on square footage.
*   Forecasting sales based on advertising spending.
*   Estimating a person's weight based on their height.

---
*ðŸŒ³ **Parent Branch:** [[Supervised Learning]]
*ðŸ“ˆ **Type:** [[Regression]]
*ðŸŒ¿ **See Also:** Its cousin for classification, [[Logistic Regression]].
